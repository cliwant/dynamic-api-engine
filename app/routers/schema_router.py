"""
ìŠ¤í‚¤ë§ˆ ë¼ìš°í„°
DB í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ, API í…ŒìŠ¤íŠ¸, LLM ê¸°ë°˜ API ìƒì„±
"""
from typing import Optional, Any
from fastapi import APIRouter, Depends, HTTPException, Query
from pydantic import BaseModel
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import get_db
from app.schemas.common import ResponseBase
from app.services import schema_service
from app.services.llm_service import (
    get_supported_models,
    get_auth_methods,
    get_providers,
    check_llm_availability,
    generate_api_spec,
    ApiGenerationRequest,
    TableSchema,
    LLMConfig,
    GeneratedApiSpec,
    # AI ê¸°ëŠ¥ í™•ì¥
    optimize_sql,
    generate_test_cases,
    process_natural_language_query,
    SqlOptimizationRequest,
    TestCaseGenerationRequest,
    NaturalLanguageQueryRequest,
)

router = APIRouter(prefix="/schema", tags=["Schema & LLM"])


# ==================== í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ====================

@router.get(
    "/tables",
    summary="í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ",
    description="í˜„ì¬ DBì˜ ëª¨ë“  í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
)
async def list_tables(
    db: AsyncSession = Depends(get_db),
):
    """DB í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
    tables = await schema_service.get_table_list(db)
    return ResponseBase(data=tables)


@router.get(
    "/tables/{table_name}",
    summary="í…Œì´ë¸” ìƒì„¸ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ",
    description="íŠ¹ì • í…Œì´ë¸”ì˜ ì»¬ëŸ¼, ì¸ë±ìŠ¤, ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
)
async def get_table_schema(
    table_name: str,
    sample_limit: int = Query(5, ge=1, le=20, description="ìƒ˜í”Œ ë°ì´í„° í–‰ ìˆ˜"),
    db: AsyncSession = Depends(get_db),
):
    """í…Œì´ë¸” ìƒì„¸ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ (ì»¬ëŸ¼, ì¸ë±ìŠ¤, ìƒ˜í”Œ ë°ì´í„°)"""
    columns = await schema_service.get_table_columns(db, table_name)
    if not columns:
        raise HTTPException(
            status_code=404,
            detail={"error": "NOT_FOUND", "message": f"í…Œì´ë¸” '{table_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        )
    
    indexes = await schema_service.get_table_indexes(db, table_name)
    sample_data = await schema_service.get_table_sample_data(db, table_name, sample_limit)
    
    # ê° ì»¬ëŸ¼ë³„ ìƒ˜í”Œ ê°’ ì¶”ì¶œ
    column_samples = {}
    for col in columns:
        col_name = col["name"]
        column_samples[col_name] = [row.get(col_name) for row in sample_data if row.get(col_name) is not None][:5]
    
    return ResponseBase(data={
        "table_name": table_name,
        "columns": columns,
        "indexes": indexes,
        "sample_data": sample_data,
        "column_samples": column_samples,
    })


@router.get(
    "/tables/{table_name}/columns",
    summary="í…Œì´ë¸” ì»¬ëŸ¼ ì¡°íšŒ",
)
async def get_table_columns(
    table_name: str,
    db: AsyncSession = Depends(get_db),
):
    """í…Œì´ë¸” ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ"""
    columns = await schema_service.get_table_columns(db, table_name)
    return ResponseBase(data=columns)


@router.get(
    "/tables/{table_name}/indexes",
    summary="í…Œì´ë¸” ì¸ë±ìŠ¤ ì¡°íšŒ",
)
async def get_table_indexes(
    table_name: str,
    db: AsyncSession = Depends(get_db),
):
    """í…Œì´ë¸” ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ"""
    indexes = await schema_service.get_table_indexes(db, table_name)
    return ResponseBase(data=indexes)


@router.get(
    "/tables/{table_name}/sample",
    summary="í…Œì´ë¸” ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ",
)
async def get_table_sample(
    table_name: str,
    limit: int = Query(5, ge=1, le=20, description="ì¡°íšŒ í–‰ ìˆ˜"),
    db: AsyncSession = Depends(get_db),
):
    """í…Œì´ë¸” ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ"""
    sample = await schema_service.get_table_sample_data(db, table_name, limit)
    return ResponseBase(data=sample)


# ==================== SQL í…ŒìŠ¤íŠ¸ ====================

class TestSqlRequest(BaseModel):
    """SQL í…ŒìŠ¤íŠ¸ ìš”ì²­"""
    logic_type: str = "SQL"
    logic_body: str
    params: dict[str, Any] = {}


@router.post(
    "/test-sql",
    summary="SQL í…ŒìŠ¤íŠ¸ ì‹¤í–‰",
    description="API ìƒì„± ì „ SQL ì¿¼ë¦¬ê°€ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.",
)
async def test_sql(
    request: TestSqlRequest,
    db: AsyncSession = Depends(get_db),
):
    """
    SQL í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    
    - ì‹¤ì œ DBì—ì„œ ì¿¼ë¦¬ ì‹¤í–‰
    - ê²°ê³¼ ë° ì‹¤í–‰ ì‹œê°„ ë°˜í™˜
    - ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
    """
    import time
    from datetime import datetime, date
    from decimal import Decimal
    
    # ìœ„í—˜í•œ ì¿¼ë¦¬ ì°¨ë‹¨
    dangerous_patterns = ["DROP ", "TRUNCATE ", "DELETE ", "ALTER ", "CREATE ", "INSERT ", "UPDATE "]
    logic_upper = request.logic_body.upper()
    for pattern in dangerous_patterns:
        if pattern in logic_upper:
            raise HTTPException(
                status_code=400,
                detail={"error": "FORBIDDEN_QUERY", "message": f"í…ŒìŠ¤íŠ¸ì—ì„œëŠ” {pattern.strip()} ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            )
    
    start_time = time.time()
    
    try:
        # SQL ì‹¤í–‰
        result = await db.execute(text(request.logic_body), request.params)
        rows = result.fetchall()
        columns = list(result.keys())
        
        # ë°ì´í„° ì§ë ¬í™”
        def serialize_value(val):
            if val is None:
                return None
            if isinstance(val, (datetime, date)):
                return val.isoformat()
            if isinstance(val, Decimal):
                return float(val)
            if isinstance(val, bytes):
                try:
                    return val.decode("utf-8")
                except:
                    return f"<bytes: {len(val)} bytes>"
            return val
        
        data = [
            {col: serialize_value(val) for col, val in zip(columns, row)}
            for row in rows
        ]
        
        execution_time = round((time.time() - start_time) * 1000, 2)
        
        return ResponseBase(
            message="í…ŒìŠ¤íŠ¸ ì„±ê³µ",
            data={
                "success": True,
                "columns": columns,
                "data": data,
                "row_count": len(data),
                "execution_time_ms": execution_time,
            }
        )
        
    except Exception as e:
        execution_time = round((time.time() - start_time) * 1000, 2)
        return ResponseBase(
            message="í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨",
            data={
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "execution_time_ms": execution_time,
            }
        )


class GetSampleValuesRequest(BaseModel):
    """ìƒ˜í”Œ ê°’ ì¡°íšŒ ìš”ì²­"""
    table_name: str
    columns: list[str]
    count: int = 5


@router.post(
    "/sample-values",
    summary="íŒŒë¼ë¯¸í„° ìƒ˜í”Œ ê°’ ì¡°íšŒ",
    description="íŠ¹ì • í…Œì´ë¸”ì˜ ì»¬ëŸ¼ì—ì„œ ì‹¤ì œ ë°ì´í„° ìƒ˜í”Œì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
)
async def get_sample_values(
    request: GetSampleValuesRequest,
    db: AsyncSession = Depends(get_db),
):
    """íŒŒë¼ë¯¸í„°ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒ˜í”Œ ê°’ ì¡°íšŒ"""
    from datetime import datetime, date
    from decimal import Decimal
    
    # í…Œì´ë¸”ëª… ê²€ì¦
    safe_table = request.table_name.replace("`", "").replace("'", "").replace('"', "")
    
    samples = {}
    for col in request.columns:
        safe_col = col.replace("`", "").replace("'", "").replace('"', "")
        try:
            query = text(f"SELECT DISTINCT `{safe_col}` FROM `{safe_table}` WHERE `{safe_col}` IS NOT NULL LIMIT :limit")
            result = await db.execute(query, {"limit": request.count})
            rows = result.fetchall()
            
            values = []
            for row in rows:
                val = row[0]
                if isinstance(val, (datetime, date)):
                    val = val.isoformat()
                elif isinstance(val, Decimal):
                    val = float(val)
                elif isinstance(val, bytes):
                    continue
                values.append(val)
            
            samples[col] = values
        except Exception as e:
            samples[col] = {"error": str(e)}
    
    return ResponseBase(data=samples)


# ==================== LLM ê´€ë ¨ ====================

@router.get(
    "/llm/models",
    summary="ì§€ì› LLM ëª¨ë¸ ëª©ë¡",
    description="ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª¨ë¸ê³¼ ì¸ì¦ ë°©ì‹ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
)
async def list_llm_models():
    """ì§€ì›ë˜ëŠ” LLM ëª¨ë¸ ëª©ë¡ ë° ì¸ì¦ ì •ë³´"""
    return ResponseBase(
        data={
            "models": get_supported_models(),
            "providers": get_providers(),
            "auth_methods": get_auth_methods(),
            "availability": check_llm_availability(),
        }
    )


@router.get(
    "/llm/status",
    summary="LLM ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€",
)
async def check_llm_status():
    """LLM ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    return ResponseBase(data=check_llm_availability())


class GenerateApiRequest(BaseModel):
    """API ìƒì„± ìš”ì²­ (í™•ì¥)"""
    user_intent: str
    table_names: list[str]
    method: str = "GET"
    # LLM ëª¨ë¸ ì„¤ì •
    model: str = "gpt-4o-mini"
    temperature: float = 0.7
    max_tokens: int = 4000
    top_p: float = 1.0
    # ì¸ì¦
    api_key: Optional[str] = None
    api_base: Optional[str] = None
    vertex_credentials: Optional[str] = None


@router.post(
    "/llm/generate-api",
    summary="LLMìœ¼ë¡œ API ìƒì„±",
    description="LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ì— ë§ëŠ” API ì •ì˜ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.",
)
async def generate_api_with_llm(
    request: GenerateApiRequest,
    db: AsyncSession = Depends(get_db),
):
    """
    LLM ê¸°ë°˜ API ìë™ ìƒì„±
    
    1. ì„ íƒí•œ í…Œì´ë¸”ë“¤ì˜ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
    2. ì‚¬ìš©ì ì˜ë„ì™€ í•¨ê»˜ LLMì— ì „ë‹¬
    3. API ì •ì˜ JSON ìƒì„±
    """
    # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
    tables = []
    for table_name in request.table_names:
        columns = await schema_service.get_table_columns(db, table_name)
        if not columns:
            continue
        indexes = await schema_service.get_table_indexes(db, table_name)
        sample_data = await schema_service.get_table_sample_data(db, table_name, 5)
        
        tables.append(TableSchema(
            table_name=table_name,
            columns=columns,
            indexes=indexes,
            sample_data=sample_data,
        ))
    
    if not tables:
        raise HTTPException(
            status_code=400,
            detail={"error": "VALIDATION_ERROR", "message": "ìœ íš¨í•œ í…Œì´ë¸”ì„ ì„ íƒí•´ì£¼ì„¸ìš”."}
        )
    
    # LLM í˜¸ì¶œ
    try:
        api_request = ApiGenerationRequest(
            user_intent=request.user_intent,
            tables=tables,
            method=request.method,
        )
        
        config = LLMConfig(
            model=request.model,
            temperature=request.temperature,
            max_tokens=request.max_tokens,
            top_p=request.top_p,
            api_key=request.api_key,
            api_base=request.api_base,
            vertex_credentials=request.vertex_credentials,
        )
        
        generated_spec = await generate_api_spec(api_request, config)
        
        return ResponseBase(
            message="API ìŠ¤í™ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            data=generated_spec.model_dump(),
        )
        
    except ImportError as e:
        raise HTTPException(
            status_code=503,
            detail={"error": "SERVICE_UNAVAILABLE", "message": str(e)}
        )
    except ValueError as e:
        raise HTTPException(
            status_code=422,
            detail={"error": "PARSING_ERROR", "message": str(e)}
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={"error": "LLM_ERROR", "message": str(e)}
        )


# ==================== AI ê¸°ëŠ¥ í™•ì¥ ====================

class OptimizeSqlRequest(BaseModel):
    """SQL ìµœì í™” ìš”ì²­"""
    sql_query: str
    table_names: list[str]
    execution_time_ms: Optional[float] = None
    # LLM ì„¤ì •
    model: str = "vertex_ai/gemini-2.5-flash"
    api_key: Optional[str] = None


@router.post(
    "/ai/optimize-sql",
    summary="ğŸ”§ SQL ìµœì í™” ì œì•ˆ",
    description="LLMì„ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ ì„±ëŠ¥ ê°œì„  ë°©ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤.",
)
async def optimize_sql_endpoint(
    request: OptimizeSqlRequest,
    db: AsyncSession = Depends(get_db),
):
    """
    SQL ìµœì í™” ì œì•ˆ
    
    - ì¸ë±ìŠ¤ í™œìš© ìµœì í™”
    - ì¿¼ë¦¬ ì¬ì‘ì„± ì œì•ˆ
    - JOIN ìˆœì„œ ìµœì í™”
    - ìƒˆ ì¸ë±ìŠ¤ ì¶”ì²œ
    """
    # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ë° ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ
    table_schemas = []
    all_indexes = []
    
    for table_name in request.table_names:
        columns = await schema_service.get_table_columns(db, table_name)
        if columns:
            table_schemas.append({
                "table_name": table_name,
                "columns": columns,
            })
        
        indexes = await schema_service.get_table_indexes(db, table_name)
        for idx in indexes:
            idx["table"] = table_name
            all_indexes.append(idx)
    
    if not table_schemas:
        raise HTTPException(
            status_code=400,
            detail={"error": "VALIDATION_ERROR", "message": "ìœ íš¨í•œ í…Œì´ë¸”ì„ ì„ íƒí•´ì£¼ì„¸ìš”."}
        )
    
    try:
        llm_request = SqlOptimizationRequest(
            sql_query=request.sql_query,
            table_schemas=table_schemas,
            indexes=all_indexes,
            execution_time_ms=request.execution_time_ms,
        )
        
        config = LLMConfig(
            model=request.model,
            api_key=request.api_key,
        )
        
        result = await optimize_sql(llm_request, config)
        
        return ResponseBase(
            message="SQL ìµœì í™” ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            data=result.model_dump(),
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={"error": "LLM_ERROR", "message": str(e)}
        )


class GenerateTestCasesRequest(BaseModel):
    """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„± ìš”ì²­"""
    route_id: str
    # LLM ì„¤ì •
    model: str = "vertex_ai/gemini-2.5-flash"
    api_key: Optional[str] = None


@router.post(
    "/ai/generate-test-cases",
    summary="ğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìë™ ìƒì„±",
    description="LLMì„ ì‚¬ìš©í•˜ì—¬ API í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.",
)
async def generate_test_cases_endpoint(
    request: GenerateTestCasesRequest,
    db: AsyncSession = Depends(get_db),
):
    """
    API í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìë™ ìƒì„±
    
    - ì •ìƒ ì¼€ì´ìŠ¤ (positive)
    - ì—ëŸ¬ ì¼€ì´ìŠ¤ (negative)
    - ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸ (boundary)
    - ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (performance)
    """
    from app.services import api_route_service, api_version_service
    
    # API ì •ë³´ ì¡°íšŒ
    route = await api_route_service.ApiRouteService.get_by_id(db, request.route_id)
    if not route:
        raise HTTPException(
            status_code=404,
            detail={"error": "NOT_FOUND", "message": "APIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        )
    
    # í˜„ì¬ ë²„ì „ ì¡°íšŒ
    version = await api_version_service.ApiVersionService.get_current(db, request.route_id)
    if not version:
        raise HTTPException(
            status_code=404,
            detail={"error": "NOT_FOUND", "message": "í˜„ì¬ ë²„ì „ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        )
    
    # ìƒ˜í”Œ ë°ì´í„° (SQLì—ì„œ í…Œì´ë¸”ëª… ì¶”ì¶œí•˜ì—¬ ì¡°íšŒ)
    sample_data = []
    if version.logic_type == "SQL":
        # ê°„ë‹¨í•œ í…Œì´ë¸”ëª… ì¶”ì¶œ (FROM ë‹¤ìŒ ë‹¨ì–´)
        import re
        match = re.search(r'FROM\s+[`"]?(\w+)[`"]?', version.logic_body, re.IGNORECASE)
        if match:
            table_name = match.group(1)
            sample_data = await schema_service.get_table_sample_data(db, table_name, 3)
    
    try:
        llm_request = TestCaseGenerationRequest(
            api_path=f"{route.method} {route.path}",
            method=route.method,
            request_spec=version.request_spec or {},
            logic_body=version.logic_body or "",
            sample_data=sample_data,
        )
        
        config = LLMConfig(
            model=request.model,
            api_key=request.api_key,
        )
        
        result = await generate_test_cases(llm_request, config)
        
        return ResponseBase(
            message="í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            data=result.model_dump(),
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={"error": "LLM_ERROR", "message": str(e)}
        )


class ChatApiRequest(BaseModel):
    """ìì—°ì–´ API í˜¸ì¶œ ìš”ì²­"""
    question: str
    auto_execute: bool = False  # Trueë©´ ìë™ìœ¼ë¡œ API ì‹¤í–‰
    # LLM ì„¤ì •
    model: str = "vertex_ai/gemini-2.5-flash"
    api_key: Optional[str] = None


@router.post(
    "/ai/chat",
    summary="ğŸ’¬ ìì—°ì–´ API í˜¸ì¶œ",
    description="ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ ì í•©í•œ APIë¥¼ ì°¾ì•„ ì‹¤í–‰í•©ë‹ˆë‹¤.",
)
async def chat_api_endpoint(
    request: ChatApiRequest,
    db: AsyncSession = Depends(get_db),
):
    """
    ìì—°ì–´ë¡œ API í˜¸ì¶œ
    
    ì˜ˆì‹œ ì§ˆë¬¸:
    - "ìµœê·¼ ê°€ì…í•œ ì‚¬ìš©ì 10ëª… ë³´ì—¬ì¤˜"
    - "í™ê¸¸ë™ íšŒì‚¬ ì •ë³´ ì¡°íšŒí•´ì¤˜"
    - "ì§„í–‰ ì¤‘ì¸ í”„ë¡œì íŠ¸ ëª©ë¡"
    """
    from app.services import api_route_service, api_version_service
    from app.services.executor_service import ExecutorService
    
    # í™œì„±í™”ëœ API ëª©ë¡ ì¡°íšŒ
    routes_data, total = await api_route_service.ApiRouteService.list_routes(db, page=1, size=100)
    
    # API ì •ë³´ ì •ë¦¬ (LLMì— ì „ë‹¬í•  í˜•ì‹)
    available_apis = []
    for route in routes_data:
        if route.is_active:
            # í˜„ì¬ ë²„ì „ ì¡°íšŒ
            version = await api_version_service.ApiVersionService.get_current_version(db, route.id)
            available_apis.append({
                "route_id": route.id,
                "path": route.path,
                "method": route.method,
                "name": route.name,
                "description": route.description or "",
                "request_spec": version.request_spec if version else {},
                "sample_params": version.sample_params if version else {},
            })
    
    if not available_apis:
        raise HTTPException(
            status_code=404,
            detail={"error": "NOT_FOUND", "message": "ì‚¬ìš© ê°€ëŠ¥í•œ APIê°€ ì—†ìŠµë‹ˆë‹¤."}
        )
    
    try:
        llm_request = NaturalLanguageQueryRequest(
            question=request.question,
            available_apis=available_apis,
        )
        
        config = LLMConfig(
            model=request.model,
            api_key=request.api_key,
        )
        
        result = await process_natural_language_query(llm_request, config)
        
        response_data = {
            "question": result.question,
            "interpretation": {
                "selected_api": result.selected_api,
                "params": result.params,
                "confidence": result.confidence,
                "explanation": result.explanation,
                "alternatives": result.alternative_apis,
            },
            "execution_result": None,
        }
        
        # ìë™ ì‹¤í–‰ ì˜µì…˜ì´ ì¼œì ¸ ìˆê³  APIê°€ ì„ íƒë˜ì—ˆìœ¼ë©´ ì‹¤í–‰
        if request.auto_execute and result.selected_api and result.confidence >= 0.7:
            try:
                route_id = result.selected_api.get("route_id")
                version = await api_version_service.ApiVersionService.get_current(db, route_id)
                
                if version:
                    # API ì‹¤í–‰
                    exec_result = await ExecutorService.execute(
                        db=db,
                        logic_type=version.logic_type,
                        logic_body=version.logic_body,
                        params=result.params,
                    )
                    
                    response_data["execution_result"] = {
                        "success": True,
                        "data": exec_result,
                    }
                    
            except Exception as exec_error:
                response_data["execution_result"] = {
                    "success": False,
                    "error": str(exec_error),
                }
        
        return ResponseBase(
            message="ìì—°ì–´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤." if not response_data["execution_result"] else "APIê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.",
            data=response_data,
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={"error": "LLM_ERROR", "message": str(e)}
        )
