"""
LLM ì„œë¹„ìŠ¤
LiteLLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ LLM ëª¨ë¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
API ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
"""
import json
import os
from pathlib import Path
from typing import Optional, Any
from pydantic import BaseModel

try:
    import litellm
    LITELLM_AVAILABLE = True
except ImportError:
    LITELLM_AVAILABLE = False

# gcloud-key.json ê²½ë¡œ ìë™ ì„¤ì •
GCLOUD_KEY_PATH = Path(__file__).parent.parent.parent / "gcloud-key.json"
if GCLOUD_KEY_PATH.exists() and not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(GCLOUD_KEY_PATH)
    print(f"âœ… Vertex AI ì¸ì¦ ì„¤ì •ë¨: {GCLOUD_KEY_PATH}")


class LLMConfig(BaseModel):
    """LLM ì„¤ì •"""
    model: str = "vertex_ai/gemini-2.5-flash"  # ê¸°ë³¸ê°’: Vertex AI Gemini 2.5 Flash
    temperature: float = 0.7
    max_tokens: int = 4000
    top_p: float = 1.0
    frequency_penalty: float = 0.0
    presence_penalty: float = 0.0
    # ì¸ì¦ ì„¤ì •
    api_key: Optional[str] = None
    api_base: Optional[str] = None
    vertex_credentials: Optional[str] = None  # gcloud-key.json ë‚´ìš©
    vertex_project: str = "cliwant-403702"  # í”„ë¡œì íŠ¸ ID
    vertex_location: str = "us-central1"  # ë¦¬ì „


class TableSchema(BaseModel):
    """í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´"""
    table_name: str
    columns: list[dict]
    indexes: list[dict]
    sample_data: list[dict]


class ApiGenerationRequest(BaseModel):
    """API ìƒì„± ìš”ì²­"""
    user_intent: str
    tables: list[TableSchema]
    method: str = "GET"


class GeneratedApiSpec(BaseModel):
    """ìƒì„±ëœ API ìŠ¤í™"""
    path: str
    method: str
    name: str
    description: str
    tags: Optional[str] = None
    logic_type: str
    logic_body: str
    request_spec: dict
    response_spec: Optional[dict] = None
    sample_params: dict
    change_note: str


# LiteLLM ì§€ì› ëª¨ë¸ ëª©ë¡ (ì£¼ìš” í”„ë¡œë°”ì´ë”) - Vertex AIë¥¼ ë¨¼ì € ë°°ì¹˜
# Vertex AI GeminiëŠ” 2.5 ì´ìƒ ë²„ì „ë§Œ ì‚¬ìš© ê°€ëŠ¥ (2.5 ~ 3.0)
SUPPORTED_MODELS = [
    # Vertex AI (Google Cloud) - Gemini 2.5+ ì „ìš©, gcloud-key.json ìë™ ì¸ì¦
    {"id": "vertex_ai/gemini-2.5-flash", "name": "âœ¨ Gemini 2.5 Flash (Vertex)", "provider": "vertex_ai", "auth": "vertex", "default": True},
    {"id": "vertex_ai/gemini-2.5-pro", "name": "ğŸš€ Gemini 2.5 Pro (Vertex)", "provider": "vertex_ai", "auth": "vertex"},
    {"id": "vertex_ai/gemini-2.5-flash-preview-05-20", "name": "Gemini 2.5 Flash Preview (Vertex)", "provider": "vertex_ai", "auth": "vertex"},
    {"id": "vertex_ai/gemini-2.5-pro-preview-05-06", "name": "Gemini 2.5 Pro Preview (Vertex)", "provider": "vertex_ai", "auth": "vertex"},
    # Gemini 3.0 (í–¥í›„ ì¶œì‹œ ì˜ˆì •)
    {"id": "vertex_ai/gemini-3.0-flash", "name": "âš¡ Gemini 3.0 Flash (Vertex)", "provider": "vertex_ai", "auth": "vertex"},
    {"id": "vertex_ai/gemini-3.0-pro", "name": "ğŸŒŸ Gemini 3.0 Pro (Vertex)", "provider": "vertex_ai", "auth": "vertex"},
    # Vertex AI Claude (non-Gemini)
    {"id": "vertex_ai/claude-3-5-sonnet@20241022", "name": "Claude 3.5 Sonnet (Vertex)", "provider": "vertex_ai", "auth": "vertex"},
    {"id": "vertex_ai/claude-3-5-haiku@20241022", "name": "Claude 3.5 Haiku (Vertex)", "provider": "vertex_ai", "auth": "vertex"},
    
    # Google AI (Gemini) - API Key ë°©ì‹
    {"id": "gemini/gemini-2.5-flash", "name": "Gemini 2.5 Flash", "provider": "google", "auth": "api_key"},
    {"id": "gemini/gemini-2.5-pro", "name": "Gemini 2.5 Pro", "provider": "google", "auth": "api_key"},
    {"id": "gemini/gemini-2.5-flash-preview-05-20", "name": "Gemini 2.5 Flash Preview", "provider": "google", "auth": "api_key"},
    
    # OpenAI
    {"id": "gpt-4o", "name": "GPT-4o", "provider": "openai", "auth": "api_key"},
    {"id": "gpt-4o-mini", "name": "GPT-4o Mini", "provider": "openai", "auth": "api_key"},
    {"id": "gpt-4-turbo", "name": "GPT-4 Turbo", "provider": "openai", "auth": "api_key"},
    {"id": "gpt-4", "name": "GPT-4", "provider": "openai", "auth": "api_key"},
    {"id": "gpt-3.5-turbo", "name": "GPT-3.5 Turbo", "provider": "openai", "auth": "api_key"},
    {"id": "o1-preview", "name": "O1 Preview", "provider": "openai", "auth": "api_key"},
    {"id": "o1-mini", "name": "O1 Mini", "provider": "openai", "auth": "api_key"},
    
    # Anthropic
    {"id": "claude-3-5-sonnet-20241022", "name": "Claude 3.5 Sonnet", "provider": "anthropic", "auth": "api_key"},
    {"id": "claude-3-5-haiku-20241022", "name": "Claude 3.5 Haiku", "provider": "anthropic", "auth": "api_key"},
    {"id": "claude-3-opus-20240229", "name": "Claude 3 Opus", "provider": "anthropic", "auth": "api_key"},
    {"id": "claude-3-sonnet-20240229", "name": "Claude 3 Sonnet", "provider": "anthropic", "auth": "api_key"},
    {"id": "claude-3-haiku-20240307", "name": "Claude 3 Haiku", "provider": "anthropic", "auth": "api_key"},
    
    # Azure OpenAI
    {"id": "azure/gpt-4o", "name": "GPT-4o (Azure)", "provider": "azure", "auth": "azure"},
    {"id": "azure/gpt-4", "name": "GPT-4 (Azure)", "provider": "azure", "auth": "azure"},
    {"id": "azure/gpt-35-turbo", "name": "GPT-3.5 Turbo (Azure)", "provider": "azure", "auth": "azure"},
    
    # AWS Bedrock
    {"id": "bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0", "name": "Claude 3.5 Sonnet (Bedrock)", "provider": "bedrock", "auth": "aws"},
    {"id": "bedrock/anthropic.claude-3-haiku-20240307-v1:0", "name": "Claude 3 Haiku (Bedrock)", "provider": "bedrock", "auth": "aws"},
    {"id": "bedrock/amazon.titan-text-express-v1", "name": "Titan Text Express (Bedrock)", "provider": "bedrock", "auth": "aws"},
    
    # Mistral
    {"id": "mistral/mistral-large-latest", "name": "Mistral Large", "provider": "mistral", "auth": "api_key"},
    {"id": "mistral/mistral-medium-latest", "name": "Mistral Medium", "provider": "mistral", "auth": "api_key"},
    {"id": "mistral/mistral-small-latest", "name": "Mistral Small", "provider": "mistral", "auth": "api_key"},
    {"id": "mistral/codestral-latest", "name": "Codestral", "provider": "mistral", "auth": "api_key"},
    
    # Groq
    {"id": "groq/llama-3.3-70b-versatile", "name": "Llama 3.3 70B (Groq)", "provider": "groq", "auth": "api_key"},
    {"id": "groq/llama-3.1-8b-instant", "name": "Llama 3.1 8B (Groq)", "provider": "groq", "auth": "api_key"},
    {"id": "groq/mixtral-8x7b-32768", "name": "Mixtral 8x7B (Groq)", "provider": "groq", "auth": "api_key"},
    
    # Together AI
    {"id": "together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo", "name": "Llama 3.1 70B (Together)", "provider": "together_ai", "auth": "api_key"},
    {"id": "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1", "name": "Mixtral 8x7B (Together)", "provider": "together_ai", "auth": "api_key"},
    
    # Ollama (ë¡œì»¬)
    {"id": "ollama/llama3.2", "name": "Llama 3.2 (Ollama)", "provider": "ollama", "auth": "none"},
    {"id": "ollama/mistral", "name": "Mistral (Ollama)", "provider": "ollama", "auth": "none"},
    {"id": "ollama/codellama", "name": "CodeLlama (Ollama)", "provider": "ollama", "auth": "none"},
    
    # OpenRouter
    {"id": "openrouter/openai/gpt-4o", "name": "GPT-4o (OpenRouter)", "provider": "openrouter", "auth": "api_key"},
    {"id": "openrouter/anthropic/claude-3.5-sonnet", "name": "Claude 3.5 Sonnet (OpenRouter)", "provider": "openrouter", "auth": "api_key"},
    {"id": "openrouter/google/gemini-pro-1.5", "name": "Gemini 1.5 Pro (OpenRouter)", "provider": "openrouter", "auth": "api_key"},
]

# ì¸ì¦ ë°©ì‹ ì„¤ëª…
AUTH_METHODS = {
    "api_key": {
        "name": "API Key",
        "description": "API í‚¤ë¥¼ ì§ì ‘ ì…ë ¥í•©ë‹ˆë‹¤.",
        "fields": [{"name": "api_key", "label": "API Key", "type": "password", "required": True}]
    },
    "vertex": {
        "name": "Google Cloud (Vertex AI)",
        "description": "Google Cloud ì„œë¹„ìŠ¤ ê³„ì • JSON í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "fields": [
            {"name": "vertex_credentials", "label": "Service Account JSON", "type": "textarea", "required": True},
            {"name": "vertex_project", "label": "Project ID", "type": "text", "required": True},
            {"name": "vertex_location", "label": "Location", "type": "text", "required": False, "default": "us-central1"}
        ]
    },
    "azure": {
        "name": "Azure OpenAI",
        "description": "Azure OpenAI ì—”ë“œí¬ì¸íŠ¸ì™€ API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "fields": [
            {"name": "api_key", "label": "API Key", "type": "password", "required": True},
            {"name": "api_base", "label": "Endpoint URL", "type": "text", "required": True},
            {"name": "api_version", "label": "API Version", "type": "text", "required": False, "default": "2024-02-01"}
        ]
    },
    "aws": {
        "name": "AWS Bedrock",
        "description": "AWS ìê²© ì¦ëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "fields": [
            {"name": "aws_access_key_id", "label": "Access Key ID", "type": "text", "required": True},
            {"name": "aws_secret_access_key", "label": "Secret Access Key", "type": "password", "required": True},
            {"name": "aws_region", "label": "Region", "type": "text", "required": False, "default": "us-east-1"}
        ]
    },
    "none": {
        "name": "ì¸ì¦ ë¶ˆí•„ìš”",
        "description": "ë¡œì»¬ ëª¨ë¸ (Ollama ë“±)",
        "fields": [{"name": "api_base", "label": "API Base URL", "type": "text", "required": False, "default": "http://localhost:11434"}]
    }
}


def get_supported_models() -> list[dict]:
    """ì§€ì›ë˜ëŠ” LLM ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    return SUPPORTED_MODELS


def get_auth_methods() -> dict:
    """ì¸ì¦ ë°©ì‹ ëª©ë¡ ë°˜í™˜"""
    return AUTH_METHODS


def get_providers() -> list[dict]:
    """í”„ë¡œë°”ì´ë” ëª©ë¡ ë°˜í™˜"""
    providers = {}
    for model in SUPPORTED_MODELS:
        p = model["provider"]
        if p not in providers:
            providers[p] = {"id": p, "auth": model["auth"], "models": []}
        providers[p]["models"].append(model)
    return list(providers.values())


def _build_system_prompt() -> str:
    """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return """ë‹¹ì‹ ì€ MySQL API ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì˜ë„ì™€ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ API ì •ì˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ìƒì„±í•´ì•¼ í•  JSON êµ¬ì¡°:
{
  "path": "API ê²½ë¡œ (ì˜ˆ: users/list, projects/by-type)",
  "method": "HTTP ë©”ì„œë“œ (GET, POST, PUT, DELETE)",
  "name": "API í•œê¸€ ì´ë¦„",
  "description": "API ì„¤ëª…",
  "tags": "íƒœê·¸ (ì²« ë²ˆì§¸ ê²½ë¡œ ì„¸ê·¸ë¨¼íŠ¸)",
  "logic_type": "SQL ë˜ëŠ” MULTI_SQL",
  "logic_body": "ì‹¤í–‰í•  SQL ì¿¼ë¦¬ (:param í˜•ì‹ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ë°”ì¸ë”©)",
  "request_spec": {"param_name": {"type": "string|int|float|bool", "required": true/false, "default": ê¸°ë³¸ê°’, "description": "ì„¤ëª…"}},
  "response_spec": {"type": "list|object", "description": "ì‘ë‹µ ì„¤ëª…"},
  "sample_params": {"param_name": ìƒ˜í”Œê°’},
  "change_note": "ë³€ê²½ ë…¸íŠ¸"
}

ê·œì¹™:
1. SQLì€ ë°˜ë“œì‹œ íŒŒë¼ë¯¸í„° ë°”ì¸ë”©(:param)ì„ ì‚¬ìš©í•˜ì„¸ìš”.
2. í…Œì´ë¸”ì˜ ì¸ë±ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
3. LIMITì™€ OFFSETì„ í†µí•œ í˜ì´ì§€ë„¤ì´ì…˜ì„ ê³ ë ¤í•˜ì„¸ìš”.
4. í•œê¸€ ì´ë¦„ê³¼ ì„¤ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”.
5. sample_paramsì—ëŠ” ì‹¤ì œ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜„ì‹¤ì ì¸ ê°’ì„ ë„£ìœ¼ì„¸ìš”.
6. ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""


def _build_user_prompt(request: ApiGenerationRequest) -> str:
    """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    tables_info = []
    for table in request.tables:
        table_info = f"""
### í…Œì´ë¸”: {table.table_name}

**ì»¬ëŸ¼:**
{json.dumps(table.columns, indent=2, ensure_ascii=False)}

**ì¸ë±ìŠ¤:**
{json.dumps(table.indexes, indent=2, ensure_ascii=False)}

**ìƒ˜í”Œ ë°ì´í„° (ìµœëŒ€ 5í–‰):**
{json.dumps(table.sample_data[:5], indent=2, ensure_ascii=False, default=str)}
"""
        tables_info.append(table_info)
    
    return f"""ì‚¬ìš©ì ì˜ë„: {request.user_intent}

HTTP ë©”ì„œë“œ: {request.method}

## ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸”

{"".join(tables_info)}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì˜ë„ì— ë§ëŠ” API ì •ì˜ JSONì„ ìƒì„±í•´ì£¼ì„¸ìš”."""


def _setup_vertex_auth(config: LLMConfig) -> None:
    """Vertex AI ì¸ì¦ ì„¤ì •"""
    # gcloud-key.json íŒŒì¼ì´ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
    if os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
        return
    
    # vertex_credentialsê°€ ì œê³µëœ ê²½ìš° ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    if config.vertex_credentials:
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            f.write(config.vertex_credentials)
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = f.name


async def generate_api_spec(
    request: ApiGenerationRequest,
    config: LLMConfig = LLMConfig()
) -> GeneratedApiSpec:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ API ìŠ¤í™ ìƒì„±
    """
    if not LITELLM_AVAILABLE:
        raise ImportError("litellm ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install litellmì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    
    # Vertex AI ì¸ì¦ ì„¤ì •
    if config.vertex_credentials:
        _setup_vertex_auth(config)
    
    system_prompt = _build_system_prompt()
    user_prompt = _build_user_prompt(request)
    
    # LiteLLM í˜¸ì¶œ íŒŒë¼ë¯¸í„° êµ¬ì„±
    completion_kwargs = {
        "model": config.model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": config.temperature,
        "max_tokens": config.max_tokens,
        "top_p": config.top_p,
    }
    
    # Vertex AI ì„¤ì •
    if config.model.startswith("vertex_ai/"):
        completion_kwargs["vertex_project"] = config.vertex_project
        completion_kwargs["vertex_location"] = config.vertex_location
    
    # API í‚¤/ë² ì´ìŠ¤ ì„¤ì •
    if config.api_key:
        completion_kwargs["api_key"] = config.api_key
    if config.api_base:
        completion_kwargs["api_base"] = config.api_base
    
    try:
        response = await litellm.acompletion(**completion_kwargs)
        
        content = response.choices[0].message.content.strip()
        
        # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì²˜ë¦¬)
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()
        
        # JSON íŒŒì‹±
        spec_dict = json.loads(content)
        
        return GeneratedApiSpec(**spec_dict)
        
    except json.JSONDecodeError as e:
        raise ValueError(f"LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        raise RuntimeError(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")


def check_llm_availability() -> dict:
    """LLM ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    result = {
        "litellm_installed": LITELLM_AVAILABLE,
        "env_keys": {
            "openai": bool(os.getenv("OPENAI_API_KEY")),
            "anthropic": bool(os.getenv("ANTHROPIC_API_KEY")),
            "google": bool(os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")),
            "vertex": bool(os.getenv("GOOGLE_APPLICATION_CREDENTIALS")),
            "azure": bool(os.getenv("AZURE_API_KEY")),
            "aws": bool(os.getenv("AWS_ACCESS_KEY_ID")),
            "mistral": bool(os.getenv("MISTRAL_API_KEY")),
            "groq": bool(os.getenv("GROQ_API_KEY")),
            "together": bool(os.getenv("TOGETHER_API_KEY")),
            "openrouter": bool(os.getenv("OPENROUTER_API_KEY")),
        }
    }
    
    result["available"] = result["litellm_installed"] and any(result["env_keys"].values())
    
    return result


# ==================== AI ê¸°ëŠ¥ í™•ì¥ ====================

class SqlOptimizationRequest(BaseModel):
    """SQL ìµœì í™” ìš”ì²­"""
    sql_query: str
    table_schemas: list[dict]  # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´
    indexes: list[dict] = []   # ì‚¬ìš© ê°€ëŠ¥í•œ ì¸ë±ìŠ¤
    execution_time_ms: Optional[float] = None  # í˜„ì¬ ì‹¤í–‰ ì‹œê°„


class SqlOptimizationResult(BaseModel):
    """SQL ìµœì í™” ê²°ê³¼"""
    original_query: str
    optimized_query: str
    suggestions: list[dict]  # [{"type": "INDEX", "message": "...", "priority": "HIGH"}]
    index_recommendations: list[dict]  # ìƒˆ ì¸ë±ìŠ¤ ì œì•ˆ
    explanation: str
    estimated_improvement: Optional[str] = None


class TestCaseGenerationRequest(BaseModel):
    """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„± ìš”ì²­"""
    api_path: str
    method: str
    request_spec: dict
    logic_body: str
    sample_data: list[dict] = []


class TestCase(BaseModel):
    """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤"""
    name: str
    description: str
    params: dict
    expected_behavior: str
    test_type: str  # "positive", "negative", "boundary", "performance"


class TestCaseGenerationResult(BaseModel):
    """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„± ê²°ê³¼"""
    api_path: str
    total_cases: int
    test_cases: list[TestCase]


class NaturalLanguageQueryRequest(BaseModel):
    """ìì—°ì–´ ì¿¼ë¦¬ ìš”ì²­"""
    question: str
    available_apis: list[dict]  # ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡


class NaturalLanguageQueryResult(BaseModel):
    """ìì—°ì–´ ì¿¼ë¦¬ ê²°ê³¼"""
    question: str
    selected_api: Optional[dict] = None  # ì„ íƒëœ API
    params: dict = {}  # ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°
    confidence: float = 0.0  # ì‹ ë¢°ë„ (0~1)
    explanation: str = ""  # í•´ì„ ì„¤ëª…
    alternative_apis: list[dict] = []  # ëŒ€ì•ˆ API ëª©ë¡


def _build_sql_optimization_prompt(request: SqlOptimizationRequest) -> str:
    """SQL ìµœì í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return f"""ë‹¹ì‹ ì€ MySQL ì¿¼ë¦¬ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ SQL ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ì„±ëŠ¥ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.

## ë¶„ì„ ëŒ€ìƒ ì¿¼ë¦¬
```sql
{request.sql_query}
```

## í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ
{json.dumps(request.table_schemas, indent=2, ensure_ascii=False)}

## ì‚¬ìš© ê°€ëŠ¥í•œ ì¸ë±ìŠ¤
{json.dumps(request.indexes, indent=2, ensure_ascii=False)}

{f"## í˜„ì¬ ì‹¤í–‰ ì‹œê°„: {request.execution_time_ms}ms" if request.execution_time_ms else ""}

## ìš”ì²­ì‚¬í•­
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ìµœì í™” ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì£¼ì„¸ìš”:

```json
{{
  "original_query": "ì›ë³¸ ì¿¼ë¦¬",
  "optimized_query": "ìµœì í™”ëœ ì¿¼ë¦¬",
  "suggestions": [
    {{"type": "INDEX|REWRITE|JOIN|LIMIT", "message": "ê°œì„  ì‚¬í•­ ì„¤ëª…", "priority": "HIGH|MEDIUM|LOW"}}
  ],
  "index_recommendations": [
    {{"table": "í…Œì´ë¸”ëª…", "columns": ["ì»¬ëŸ¼1", "ì»¬ëŸ¼2"], "type": "INDEX|UNIQUE|FULLTEXT", "reason": "ì´ìœ "}}
  ],
  "explanation": "ì „ë°˜ì ì¸ ì„¤ëª… (í•œê¸€)",
  "estimated_improvement": "ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ (ì˜ˆ: 50% ê°œì„ )"
}}
```

ê·œì¹™:
1. ì¸ë±ìŠ¤ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ë„ë¡ ì¿¼ë¦¬ ìˆ˜ì •
2. ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ ì œê±°
3. JOIN ìˆœì„œ ìµœì í™”
4. WHERE ì ˆ ì¡°ê±´ ìˆœì„œ ìµœì í™”
5. LIMIT í™œìš© ê¶Œì¥
6. ì„œë¸Œì¿¼ë¦¬ë³´ë‹¤ JOIN ì„ í˜¸"""


def _build_test_case_prompt(request: TestCaseGenerationRequest) -> str:
    """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„± í”„ë¡¬í”„íŠ¸"""
    return f"""ë‹¹ì‹ ì€ API í…ŒìŠ¤íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ API ì •ì˜ë¥¼ ë¶„ì„í•˜ì—¬ í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## API ì •ë³´
- ê²½ë¡œ: {request.api_path}
- ë©”ì„œë“œ: {request.method}
- ìš”ì²­ ìŠ¤í™: {json.dumps(request.request_spec, indent=2, ensure_ascii=False)}

## SQL ë¡œì§
```sql
{request.logic_body}
```

## ìƒ˜í”Œ ë°ì´í„°
{json.dumps(request.sample_data[:3], indent=2, ensure_ascii=False, default=str)}

## ìš”ì²­ì‚¬í•­
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

```json
{{
  "api_path": "API ê²½ë¡œ",
  "total_cases": í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ìˆ˜,
  "test_cases": [
    {{
      "name": "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ëª…",
      "description": "ì„¤ëª… (í•œê¸€)",
      "params": {{"param1": "value1"}},
      "expected_behavior": "ì˜ˆìƒ ë™ì‘ (í•œê¸€)",
      "test_type": "positive|negative|boundary|performance"
    }}
  ]
}}
```

í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìœ í˜•ë³„ ìµœì†Œ ê°œìˆ˜:
1. positive (ì •ìƒ ì¼€ì´ìŠ¤): 3ê°œ ì´ìƒ
2. negative (ì—ëŸ¬ ì¼€ì´ìŠ¤): 2ê°œ ì´ìƒ - í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½, ì˜ëª»ëœ íƒ€ì… ë“±
3. boundary (ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸): 2ê°œ ì´ìƒ - ë¹ˆ ë¬¸ìì—´, ìµœëŒ€/ìµœì†Œê°’, íŠ¹ìˆ˜ë¬¸ì ë“±
4. performance (ì„±ëŠ¥ í…ŒìŠ¤íŠ¸): 1ê°œ ì´ìƒ - ëŒ€ëŸ‰ ë°ì´í„° ì¡°íšŒ ë“±

ìƒ˜í”Œ ë°ì´í„°ì˜ ì‹¤ì œ ê°’ì„ í™œìš©í•˜ì—¬ í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”."""


def _build_natural_language_query_prompt(request: NaturalLanguageQueryRequest) -> str:
    """ìì—°ì–´ ì¿¼ë¦¬ í”„ë¡¬í”„íŠ¸"""
    # API ëª©ë¡ì„ ê°„ëµí•˜ê²Œ ì •ë¦¬
    apis_summary = []
    for api in request.available_apis:
        apis_summary.append({
            "route_id": api.get("route_id"),
            "path": api.get("path"),
            "method": api.get("method"),
            "name": api.get("name"),
            "description": api.get("description", ""),
            "request_spec": api.get("request_spec", {}),
        })
    
    return f"""ë‹¹ì‹ ì€ API ê²€ìƒ‰ ë° íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ APIë¥¼ ì°¾ê³  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
"{request.question}"

## ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡
{json.dumps(apis_summary, indent=2, ensure_ascii=False)}

## ìš”ì²­ì‚¬í•­
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì£¼ì„¸ìš”:

```json
{{
  "question": "ì›ë³¸ ì§ˆë¬¸",
  "selected_api": {{
    "route_id": "ì„ íƒëœ API ID",
    "path": "API ê²½ë¡œ",
    "method": "HTTP ë©”ì„œë“œ"
  }},
  "params": {{"param_name": "ì¶”ì¶œëœê°’"}},
  "confidence": 0.95,
  "explanation": "í•´ì„ ì„¤ëª… (í•œê¸€) - ì™œ ì´ APIë¥¼ ì„ íƒí–ˆê³ , íŒŒë¼ë¯¸í„°ë¥¼ ì–´ë–»ê²Œ ì¶”ì¶œí–ˆëŠ”ì§€",
  "alternative_apis": [
    {{"route_id": "ëŒ€ì•ˆ API ID", "path": "ê²½ë¡œ", "reason": "ì´ APIë„ ì‚¬ìš© ê°€ëŠ¥í•œ ì´ìœ "}}
  ]
}}
```

ê·œì¹™:
1. ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ í‚¤ì›Œë“œë¡œ ê°€ì¥ ì í•©í•œ APIë¥¼ ì°¾ìœ¼ì„¸ìš”.
2. ì§ˆë¬¸ì—ì„œ íŒŒë¼ë¯¸í„° ê°’ì„ ì¶”ì¶œí•˜ì„¸ìš” (ì˜ˆ: "í™ê¸¸ë™ ì‚¬ìš©ì" â†’ {{"user_name": "í™ê¸¸ë™"}})
3. ìˆ«ì, ë‚ ì§œ, ID ë“±ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ íŒŒë¼ë¯¸í„°ì— ë§¤í•‘í•˜ì„¸ìš”.
4. í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ confidenceë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ì„¸ìš”.
5. ì í•©í•œ APIê°€ ì—†ìœ¼ë©´ selected_apië¥¼ nullë¡œ ì„¤ì •í•˜ê³  ì„¤ëª…í•˜ì„¸ìš”.
6. ì—¬ëŸ¬ APIê°€ ê°€ëŠ¥í•˜ë©´ alternative_apisì— ì¶”ê°€í•˜ì„¸ìš”."""


async def optimize_sql(
    request: SqlOptimizationRequest,
    config: LLMConfig = LLMConfig()
) -> SqlOptimizationResult:
    """SQL ì¿¼ë¦¬ ìµœì í™” ì œì•ˆ"""
    if not LITELLM_AVAILABLE:
        raise ImportError("litellm ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    if config.vertex_credentials:
        _setup_vertex_auth(config)
    
    prompt = _build_sql_optimization_prompt(request)
    
    completion_kwargs = {
        "model": config.model,
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ MySQL ì¿¼ë¦¬ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,  # ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ ì˜¨ë„
        "max_tokens": config.max_tokens,
    }
    
    if config.model.startswith("vertex_ai/"):
        completion_kwargs["vertex_project"] = config.vertex_project
        completion_kwargs["vertex_location"] = config.vertex_location
    
    if config.api_key:
        completion_kwargs["api_key"] = config.api_key
    
    try:
        response = await litellm.acompletion(**completion_kwargs)
        content = response.choices[0].message.content.strip()
        
        # JSON ì¶”ì¶œ
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()
        
        result_dict = json.loads(content)
        return SqlOptimizationResult(**result_dict)
        
    except json.JSONDecodeError as e:
        raise ValueError(f"LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        raise RuntimeError(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")


async def generate_test_cases(
    request: TestCaseGenerationRequest,
    config: LLMConfig = LLMConfig()
) -> TestCaseGenerationResult:
    """API í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìë™ ìƒì„±"""
    if not LITELLM_AVAILABLE:
        raise ImportError("litellm ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    if config.vertex_credentials:
        _setup_vertex_auth(config)
    
    prompt = _build_test_case_prompt(request)
    
    completion_kwargs = {
        "model": config.model,
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ API í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.5,
        "max_tokens": config.max_tokens,
    }
    
    if config.model.startswith("vertex_ai/"):
        completion_kwargs["vertex_project"] = config.vertex_project
        completion_kwargs["vertex_location"] = config.vertex_location
    
    if config.api_key:
        completion_kwargs["api_key"] = config.api_key
    
    try:
        response = await litellm.acompletion(**completion_kwargs)
        content = response.choices[0].message.content.strip()
        
        # JSON ì¶”ì¶œ
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()
        
        result_dict = json.loads(content)
        return TestCaseGenerationResult(**result_dict)
        
    except json.JSONDecodeError as e:
        raise ValueError(f"LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        raise RuntimeError(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")


async def process_natural_language_query(
    request: NaturalLanguageQueryRequest,
    config: LLMConfig = LLMConfig()
) -> NaturalLanguageQueryResult:
    """ìì—°ì–´ë¡œ API í˜¸ì¶œ"""
    if not LITELLM_AVAILABLE:
        raise ImportError("litellm ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    if config.vertex_credentials:
        _setup_vertex_auth(config)
    
    prompt = _build_natural_language_query_prompt(request)
    
    completion_kwargs = {
        "model": config.model,
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì í•©í•œ APIë¥¼ ì°¾ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,
        "max_tokens": config.max_tokens,
    }
    
    if config.model.startswith("vertex_ai/"):
        completion_kwargs["vertex_project"] = config.vertex_project
        completion_kwargs["vertex_location"] = config.vertex_location
    
    if config.api_key:
        completion_kwargs["api_key"] = config.api_key
    
    try:
        response = await litellm.acompletion(**completion_kwargs)
        content = response.choices[0].message.content.strip()
        
        # JSON ì¶”ì¶œ
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()
        
        result_dict = json.loads(content)
        return NaturalLanguageQueryResult(**result_dict)
        
    except json.JSONDecodeError as e:
        raise ValueError(f"LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        raise RuntimeError(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")


# ============================================================================
# ìì—°ì–´ â†’ SQL ì¿¼ë¦¬ ìƒì„± ë° ë³´ì•ˆ ê²€ì¦ ì‹œìŠ¤í…œ
# ============================================================================

import re
from enum import Enum
from dataclasses import dataclass


class SecurityRiskLevel(str, Enum):
    """ë³´ì•ˆ ìœ„í—˜ ìˆ˜ì¤€"""
    SAFE = "safe"           # ì•ˆì „
    LOW = "low"             # ë‚®ì€ ìœ„í—˜
    MEDIUM = "medium"       # ì¤‘ê°„ ìœ„í—˜
    HIGH = "high"           # ë†’ì€ ìœ„í—˜ (ì°¨ë‹¨)
    CRITICAL = "critical"   # ì¹˜ëª…ì  ìœ„í—˜ (ì¦‰ì‹œ ì°¨ë‹¨)


class SecurityViolationType(str, Enum):
    """ë³´ì•ˆ ìœ„ë°˜ ìœ í˜•"""
    SQL_INJECTION = "sql_injection"
    DDL_COMMAND = "ddl_command"
    DANGEROUS_DML = "dangerous_dml"
    SENSITIVE_DATA = "sensitive_data"
    SYSTEM_TABLE = "system_table"
    MALICIOUS_INTENT = "malicious_intent"
    EXCESSIVE_SCOPE = "excessive_scope"
    PROHIBITED_KEYWORD = "prohibited_keyword"


@dataclass
class SecurityViolation:
    """ë³´ì•ˆ ìœ„ë°˜ ì •ë³´"""
    violation_type: SecurityViolationType
    risk_level: SecurityRiskLevel
    description: str
    matched_pattern: str = ""


class NaturalLanguageToSqlRequest(BaseModel):
    """ìì—°ì–´ â†’ SQL ë³€í™˜ ìš”ì²­"""
    question: str
    tables: list[TableSchema]
    max_rows: int = 100  # ìµœëŒ€ ë°˜í™˜ í–‰ ìˆ˜
    allow_joins: bool = True  # JOIN í—ˆìš© ì—¬ë¶€
    read_only: bool = True  # SELECTë§Œ í—ˆìš©


class SqlSecurityCheckResult(BaseModel):
    """SQL ë³´ì•ˆ ê²€ì‚¬ ê²°ê³¼"""
    is_safe: bool
    risk_level: str
    violations: list[dict]
    sanitized_query: Optional[str] = None
    blocked_reason: Optional[str] = None


class GeneratedSqlResult(BaseModel):
    """ìƒì„±ëœ SQL ì¿¼ë¦¬ ê²°ê³¼"""
    original_question: str
    sql_query: str
    explanation: str
    tables_used: list[str]
    estimated_rows: Optional[int] = None
    security_check: SqlSecurityCheckResult
    execution_allowed: bool
    warnings: list[str] = []


# ë¯¼ê° í…Œì´ë¸” íŒ¨í„´ (ì •ê·œì‹)
SENSITIVE_TABLE_PATTERNS = [
    r".*password.*",
    r".*passwd.*",
    r".*secret.*",
    r".*token.*",
    r".*credential.*",
    r".*api_key.*",
    r".*private.*",
    r".*admin.*",
    r".*auth.*",
    r".*session.*",
    r".*payment.*",
    r".*credit.*card.*",
    r".*bank.*",
    r".*ssn.*",  # Social Security Number
    r".*ì£¼ë¯¼.*ë²ˆí˜¸.*",
]

# ë¯¼ê° ì»¬ëŸ¼ íŒ¨í„´
SENSITIVE_COLUMN_PATTERNS = [
    r".*password.*",
    r".*passwd.*",
    r".*pwd.*",
    r".*secret.*",
    r".*token.*",
    r".*api_key.*",
    r".*private_key.*",
    r".*credit.*card.*",
    r".*cvv.*",
    r".*ssn.*",
    r".*ì£¼ë¯¼.*ë²ˆí˜¸.*",
    r".*ê³„ì¢Œ.*ë²ˆí˜¸.*",
    r".*ì¹´ë“œ.*ë²ˆí˜¸.*",
    r".*ë¹„ë°€ë²ˆí˜¸.*",
]

# SQL Injection íŒ¨í„´
SQL_INJECTION_PATTERNS = [
    r";\s*--",                          # ; --
    r"'\s*OR\s+'?1'?\s*=\s*'?1",       # ' OR '1'='1
    r"'\s*OR\s+''='",                   # ' OR ''='
    r"UNION\s+SELECT",                  # UNION SELECT
    r"UNION\s+ALL\s+SELECT",           # UNION ALL SELECT
    r"'\s*;\s*DROP",                    # '; DROP
    r"'\s*;\s*DELETE",                  # '; DELETE
    r"'\s*;\s*UPDATE",                  # '; UPDATE
    r"'\s*;\s*INSERT",                  # '; INSERT
    r"EXEC\s*\(",                       # EXEC(
    r"EXECUTE\s*\(",                    # EXECUTE(
    r"xp_cmdshell",                     # xp_cmdshell
    r"INTO\s+OUTFILE",                  # INTO OUTFILE
    r"INTO\s+DUMPFILE",                 # INTO DUMPFILE
    r"LOAD_FILE\s*\(",                  # LOAD_FILE(
    r"BENCHMARK\s*\(",                  # BENCHMARK(
    r"SLEEP\s*\(",                      # SLEEP(
    r"WAITFOR\s+DELAY",                 # WAITFOR DELAY
    r"0x[0-9a-fA-F]+",                  # Hex encoding
]

# ê¸ˆì§€ëœ DDL ëª…ë ¹ì–´
PROHIBITED_DDL_COMMANDS = [
    "DROP",
    "CREATE",
    "ALTER",
    "TRUNCATE",
    "RENAME",
    "GRANT",
    "REVOKE",
]

# ê¸ˆì§€ëœ DML ëª…ë ¹ì–´ (ì¡°ê±´ ì—†ì´ ì‚¬ìš© ì‹œ)
DANGEROUS_DML_COMMANDS = [
    "DELETE",
    "UPDATE",
    "INSERT",
    "REPLACE",
]

# ì‹œìŠ¤í…œ í…Œì´ë¸” íŒ¨í„´
SYSTEM_TABLE_PATTERNS = [
    r"^information_schema\.",
    r"^mysql\.",
    r"^performance_schema\.",
    r"^sys\.",
]

# ì•…ì˜ì  ì˜ë„ í‚¤ì›Œë“œ
MALICIOUS_INTENT_KEYWORDS = [
    "ì‚­ì œí•´ì¤˜",
    "ì§€ì›Œì¤˜",
    "ëª¨ë‘ ì‚­ì œ",
    "ì „ë¶€ ì‚­ì œ",
    "ë°ì´í„° ì‚­ì œ",
    "í…Œì´ë¸” ì‚­ì œ",
    "drop",
    "delete all",
    "remove all",
    "ë¹„ë°€ë²ˆí˜¸ ë³´ì—¬ì¤˜",
    "password ì¡°íšŒ",
    "í† í° ë³´ì—¬ì¤˜",
    "api key",
    "í•´í‚¹",
    "ì·¨ì•½ì ",
    "ìš°íšŒ",
    "injection",
]


def check_sql_security(sql_query: str, original_question: str = "") -> SqlSecurityCheckResult:
    """
    SQL ì¿¼ë¦¬ ë³´ì•ˆ ê²€ì‚¬
    
    ê²€ì‚¬ í•­ëª©:
    1. SQL Injection íŒ¨í„´
    2. DDL ëª…ë ¹ì–´
    3. ìœ„í—˜í•œ DML ëª…ë ¹ì–´
    4. ë¯¼ê° í…Œì´ë¸”/ì»¬ëŸ¼ ì ‘ê·¼
    5. ì‹œìŠ¤í…œ í…Œì´ë¸” ì ‘ê·¼
    6. ì•…ì˜ì  ì˜ë„
    """
    violations = []
    
    # SQL ì¿¼ë¦¬ ì •ê·œí™” (ìš°íšŒ ê³µê²© ë°©ì§€)
    # 1. ì£¼ì„ ì œê±°
    normalized_sql = re.sub(r'--.*$', ' ', sql_query, flags=re.MULTILINE)  # ë¼ì¸ ì£¼ì„
    normalized_sql = re.sub(r'/\*.*?\*/', ' ', normalized_sql, flags=re.DOTALL)  # ë¸”ë¡ ì£¼ì„
    # 2. ì—°ì† ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
    normalized_sql = re.sub(r'\s+', ' ', normalized_sql)
    # 3. ëŒ€ë¬¸ì ë³€í™˜ (ë¹„êµìš©)
    sql_upper = normalized_sql.upper().strip()
    question_lower = original_question.lower()
    
    # 1. SQL Injection íŒ¨í„´ ê²€ì‚¬ (ì›ë³¸ + ì •ê·œí™”ëœ ì¿¼ë¦¬ ëª¨ë‘ ê²€ì‚¬)
    for pattern in SQL_INJECTION_PATTERNS:
        # ì›ë³¸ ì¿¼ë¦¬ ê²€ì‚¬
        if re.search(pattern, sql_query, re.IGNORECASE):
            violations.append(SecurityViolation(
                violation_type=SecurityViolationType.SQL_INJECTION,
                risk_level=SecurityRiskLevel.CRITICAL,
                description="SQL Injection íŒ¨í„´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                matched_pattern=pattern
            ))
            continue
        # ì •ê·œí™”ëœ ì¿¼ë¦¬ ê²€ì‚¬ (ìš°íšŒ ê³µê²© ë°©ì§€)
        if re.search(pattern, normalized_sql, re.IGNORECASE):
            violations.append(SecurityViolation(
                violation_type=SecurityViolationType.SQL_INJECTION,
                risk_level=SecurityRiskLevel.CRITICAL,
                description="SQL Injection íŒ¨í„´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤ (ì£¼ì„/ê³µë°± ìš°íšŒ ì‹œë„).",
                matched_pattern=pattern
            ))
    
    # 2. DDL ëª…ë ¹ì–´ ê²€ì‚¬ (ì •ê·œí™”ëœ ì¿¼ë¦¬ ì‚¬ìš©)
    for cmd in PROHIBITED_DDL_COMMANDS:
        if re.search(rf'\b{cmd}\b', sql_upper):
            violations.append(SecurityViolation(
                violation_type=SecurityViolationType.DDL_COMMAND,
                risk_level=SecurityRiskLevel.CRITICAL,
                description=f"ê¸ˆì§€ëœ DDL ëª…ë ¹ì–´ '{cmd}'ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                matched_pattern=cmd
            ))
    
    # 3. ìœ„í—˜í•œ DML ëª…ë ¹ì–´ ê²€ì‚¬ (SELECT ì™¸ì˜ ëª…ë ¹ì–´)
    for cmd in DANGEROUS_DML_COMMANDS:
        if re.search(rf'\b{cmd}\b', sql_upper):
            violations.append(SecurityViolation(
                violation_type=SecurityViolationType.DANGEROUS_DML,
                risk_level=SecurityRiskLevel.HIGH,
                description=f"ìœ„í—˜í•œ DML ëª…ë ¹ì–´ '{cmd}'ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì½ê¸° ì „ìš© ì¿¼ë¦¬ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.",
                matched_pattern=cmd
            ))
    
    # 4. ë¯¼ê° í…Œì´ë¸” ì ‘ê·¼ ê²€ì‚¬
    for pattern in SENSITIVE_TABLE_PATTERNS:
        if re.search(pattern, sql_query, re.IGNORECASE):
            violations.append(SecurityViolation(
                violation_type=SecurityViolationType.SENSITIVE_DATA,
                risk_level=SecurityRiskLevel.HIGH,
                description="ë¯¼ê°í•œ ë°ì´í„° í…Œì´ë¸”ì— ëŒ€í•œ ì ‘ê·¼ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                matched_pattern=pattern
            ))
    
    # 5. ë¯¼ê° ì»¬ëŸ¼ ì ‘ê·¼ ê²€ì‚¬
    for pattern in SENSITIVE_COLUMN_PATTERNS:
        if re.search(pattern, sql_query, re.IGNORECASE):
            violations.append(SecurityViolation(
                violation_type=SecurityViolationType.SENSITIVE_DATA,
                risk_level=SecurityRiskLevel.HIGH,
                description="ë¯¼ê°í•œ ë°ì´í„° ì»¬ëŸ¼ì— ëŒ€í•œ ì ‘ê·¼ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                matched_pattern=pattern
            ))
    
    # 6. ì‹œìŠ¤í…œ í…Œì´ë¸” ì ‘ê·¼ ê²€ì‚¬
    for pattern in SYSTEM_TABLE_PATTERNS:
        if re.search(pattern, sql_query, re.IGNORECASE):
            violations.append(SecurityViolation(
                violation_type=SecurityViolationType.SYSTEM_TABLE,
                risk_level=SecurityRiskLevel.MEDIUM,
                description="ì‹œìŠ¤í…œ í…Œì´ë¸”ì— ëŒ€í•œ ì ‘ê·¼ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                matched_pattern=pattern
            ))
    
    # 7. ì•…ì˜ì  ì˜ë„ ê²€ì‚¬ (ì›ë³¸ ì§ˆë¬¸)
    for keyword in MALICIOUS_INTENT_KEYWORDS:
        if keyword.lower() in question_lower:
            violations.append(SecurityViolation(
                violation_type=SecurityViolationType.MALICIOUS_INTENT,
                risk_level=SecurityRiskLevel.HIGH,
                description=f"ì•…ì˜ì  ì˜ë„ê°€ ì˜ì‹¬ë˜ëŠ” í‚¤ì›Œë“œ '{keyword}'ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                matched_pattern=keyword
            ))
    
    # 8. SELECT ë¬¸ì´ ì•„ë‹Œ ê²½ìš° (ì½ê¸° ì „ìš© ëª¨ë“œ)
    if not sql_upper.startswith("SELECT"):
        violations.append(SecurityViolation(
            violation_type=SecurityViolationType.DANGEROUS_DML,
            risk_level=SecurityRiskLevel.HIGH,
            description="SELECT ë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤. ì½ê¸° ì „ìš© ì¿¼ë¦¬ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.",
            matched_pattern="NON_SELECT"
        ))
    
    # ìœ„í—˜ ìˆ˜ì¤€ ê²°ì •
    if any(v.risk_level == SecurityRiskLevel.CRITICAL for v in violations):
        overall_risk = SecurityRiskLevel.CRITICAL
    elif any(v.risk_level == SecurityRiskLevel.HIGH for v in violations):
        overall_risk = SecurityRiskLevel.HIGH
    elif any(v.risk_level == SecurityRiskLevel.MEDIUM for v in violations):
        overall_risk = SecurityRiskLevel.MEDIUM
    elif any(v.risk_level == SecurityRiskLevel.LOW for v in violations):
        overall_risk = SecurityRiskLevel.LOW
    else:
        overall_risk = SecurityRiskLevel.SAFE
    
    is_safe = overall_risk == SecurityRiskLevel.SAFE
    blocked_reason = None
    
    if not is_safe:
        blocked_reason = "; ".join([v.description for v in violations[:3]])  # ìƒìœ„ 3ê°œ ì´ìœ 
    
    return SqlSecurityCheckResult(
        is_safe=is_safe,
        risk_level=overall_risk.value,
        violations=[{
            "type": v.violation_type.value,
            "risk_level": v.risk_level.value,
            "description": v.description,
            "pattern": v.matched_pattern
        } for v in violations],
        sanitized_query=sql_query if is_safe else None,
        blocked_reason=blocked_reason
    )


def check_question_intent(question: str) -> tuple[bool, list[str]]:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ê²€ì‚¬í•˜ì—¬ ì•…ì˜ì ì¸ì§€ íŒë‹¨
    
    Returns:
        (is_safe, warnings): ì•ˆì „ ì—¬ë¶€ì™€ ê²½ê³  ë©”ì‹œì§€ ëª©ë¡
    """
    warnings = []
    question_lower = question.lower()
    
    # ì•…ì˜ì  ì˜ë„ í‚¤ì›Œë“œ ê²€ì‚¬
    for keyword in MALICIOUS_INTENT_KEYWORDS:
        if keyword.lower() in question_lower:
            return False, [f"'{keyword}'ì™€ ê´€ë ¨ëœ ìš”ì²­ì€ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    
    # ë°ì´í„° ìˆ˜ì •/ì‚­ì œ ì˜ë„ ê²€ì‚¬
    modification_patterns = [
        (r"ì‚­ì œ|ì§€ìš°|ì œê±°|drop|delete|remove", "ë°ì´í„° ì‚­ì œ"),
        (r"ìˆ˜ì •|ë³€ê²½|ì—…ë°ì´íŠ¸|update|modify|change", "ë°ì´í„° ìˆ˜ì •"),
        (r"ì¶”ê°€|ì…ë ¥|ì‚½ì…|insert|add|create", "ë°ì´í„° ì¶”ê°€"),
    ]
    
    for pattern, description in modification_patterns:
        if re.search(pattern, question_lower):
            warnings.append(f"'{description}' ê´€ë ¨ ìš”ì²­ì€ ì½ê¸° ì „ìš© ëª¨ë“œì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    # ë¯¼ê° ì •ë³´ ìš”ì²­ ê²€ì‚¬
    sensitive_patterns = [
        (r"ë¹„ë°€ë²ˆí˜¸|password|pwd|passwd", "ë¹„ë°€ë²ˆí˜¸"),
        (r"ì£¼ë¯¼.*ë²ˆí˜¸|ssn|social.*security", "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸"),
        (r"ì¹´ë“œ.*ë²ˆí˜¸|credit.*card|cvv", "ì¹´ë“œë²ˆí˜¸"),
        (r"ê³„ì¢Œ.*ë²ˆí˜¸|bank.*account", "ê³„ì¢Œë²ˆí˜¸"),
        (r"í† í°|token|api.*key|secret", "ì¸ì¦ í† í°"),
    ]
    
    for pattern, description in sensitive_patterns:
        if re.search(pattern, question_lower):
            return False, [f"'{description}' ê´€ë ¨ ë¯¼ê° ì •ë³´ëŠ” ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    
    return True, warnings


def sanitize_sql_query(sql_query: str, max_rows: int = 100) -> str:
    """
    SQL ì¿¼ë¦¬ ì •ì œ ë° LIMIT ê°•ì œ ì ìš©
    """
    sql_query = sql_query.strip()
    
    # ì„¸ë¯¸ì½œë¡  ì œê±° (ë‹¤ì¤‘ ì¿¼ë¦¬ ë°©ì§€)
    sql_query = sql_query.rstrip(';')
    
    # ì£¼ì„ ì œê±°
    sql_query = re.sub(r'--.*$', '', sql_query, flags=re.MULTILINE)
    sql_query = re.sub(r'/\*.*?\*/', '', sql_query, flags=re.DOTALL)
    
    # LIMIT ê°•ì œ ì ìš©
    sql_upper = sql_query.upper()
    if "LIMIT" not in sql_upper:
        sql_query = f"{sql_query} LIMIT {max_rows}"
    else:
        # ê¸°ì¡´ LIMIT ê°’ì´ max_rowsë³´ë‹¤ í¬ë©´ ì œí•œ
        limit_match = re.search(r'LIMIT\s+(\d+)', sql_upper)
        if limit_match:
            current_limit = int(limit_match.group(1))
            if current_limit > max_rows:
                sql_query = re.sub(
                    r'LIMIT\s+\d+',
                    f'LIMIT {max_rows}',
                    sql_query,
                    flags=re.IGNORECASE
                )
    
    return sql_query


def _build_natural_language_to_sql_prompt(request: NaturalLanguageToSqlRequest) -> str:
    """ìì—°ì–´ â†’ SQL ë³€í™˜ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´ êµ¬ì„±
    tables_info = []
    for table in request.tables:
        columns_str = "\n      ".join([
            f"- {col.get('column_name', col.get('name', 'unknown'))}: "
            f"{col.get('data_type', col.get('type', 'unknown'))} "
            f"{'(PK)' if col.get('is_primary_key') or col.get('column_key') == 'PRI' else ''} "
            f"{'(nullable)' if col.get('is_nullable') == 'YES' else ''}"
            f"{' - ' + col.get('column_comment', '') if col.get('column_comment') else ''}"
            for col in table.columns
        ])
        
        sample_str = ""
        if table.sample_data:
            sample_str = f"\n    ìƒ˜í”Œ ë°ì´í„° (ìµœëŒ€ 3í–‰):\n      {json.dumps(table.sample_data[:3], ensure_ascii=False, indent=6)}"
        
        tables_info.append(f"""
    í…Œì´ë¸”: {table.table_name}
    ì»¬ëŸ¼:
      {columns_str}{sample_str}
""")
    
    tables_schema = "\n".join(tables_info)
    
    return f"""ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì•ˆì „í•œ MySQL SELECT ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.

## ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸”
{tables_schema}

## ì‚¬ìš©ì ì§ˆë¬¸
"{request.question}"

## ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
1. **SELECT ë¬¸ë§Œ ìƒì„±**: ì ˆëŒ€ë¡œ INSERT, UPDATE, DELETE, DROP ë“± ë°ì´í„° ìˆ˜ì • ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
2. **ë¯¼ê° ì •ë³´ ì œì™¸**: ë¹„ë°€ë²ˆí˜¸, í† í°, ì¹´ë“œë²ˆí˜¸, ì£¼ë¯¼ë²ˆí˜¸ ë“± ë¯¼ê°í•œ ì»¬ëŸ¼ì€ SELECTì—ì„œ ì œì™¸í•˜ì„¸ìš”.
3. **LIMIT ì ìš©**: ê²°ê³¼ í–‰ ìˆ˜ë¥¼ {request.max_rows}ê°œë¡œ ì œí•œí•˜ì„¸ìš”.
4. **ëª…í™•í•œ ì»¬ëŸ¼ ì„ íƒ**: SELECT *ëŠ” í”¼í•˜ê³ , í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ëª…ì‹œí•˜ì„¸ìš”.
5. **JOIN ì œí•œ**: {"JOINì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤." if request.allow_joins else "JOINì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."}
6. **ì•ˆì „í•œ WHERE ì ˆ**: ì‚¬ìš©ì ì…ë ¥ê°’ì€ íŒŒë¼ë¯¸í„°ë¡œ ì²˜ë¦¬ë  ê²ƒì´ë¯€ë¡œ ì§ì ‘ ê°’ì„ ë„£ì–´ë„ ë©ë‹ˆë‹¤.

## ì‘ë‹µ í˜•ì‹ (JSON)
```json
{{
  "sql_query": "ìƒì„±ëœ SELECT ì¿¼ë¦¬",
  "explanation": "ì¿¼ë¦¬ ì„¤ëª… (í•œêµ­ì–´)",
  "tables_used": ["ì‚¬ìš©ëœ í…Œì´ë¸” ëª©ë¡"],
  "estimated_rows": null,
  "warnings": ["ì£¼ì˜ì‚¬í•­ ëª©ë¡"],
  "confidence": 0.0~1.0
}}
```

## ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ìš”ì²­ì˜ ê²½ìš°
```json
{{
  "sql_query": null,
  "explanation": "ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ì´ìœ ",
  "tables_used": [],
  "estimated_rows": null,
  "warnings": ["ê²½ê³  ë©”ì‹œì§€"],
  "confidence": 0.0
}}
```"""


async def generate_sql_from_natural_language(
    request: NaturalLanguageToSqlRequest,
    config: LLMConfig = LLMConfig()
) -> GeneratedSqlResult:
    """
    ìì—°ì–´ë¥¼ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜
    
    ë³´ì•ˆ ê²€ì¦ í”„ë¡œì„¸ìŠ¤:
    1. ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ê²€ì‚¬
    2. LLMì„ í†µí•œ SQL ìƒì„±
    3. ìƒì„±ëœ SQL ë³´ì•ˆ ê²€ì‚¬
    4. SQL ì •ì œ ë° LIMIT ì ìš©
    """
    if not LITELLM_AVAILABLE:
        raise ImportError("litellm ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    # 1ë‹¨ê³„: ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ê²€ì‚¬
    is_question_safe, intent_warnings = check_question_intent(request.question)
    
    if not is_question_safe:
        return GeneratedSqlResult(
            original_question=request.question,
            sql_query="",
            explanation=intent_warnings[0] if intent_warnings else "ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            tables_used=[],
            security_check=SqlSecurityCheckResult(
                is_safe=False,
                risk_level=SecurityRiskLevel.HIGH.value,
                violations=[{
                    "type": SecurityViolationType.MALICIOUS_INTENT.value,
                    "risk_level": SecurityRiskLevel.HIGH.value,
                    "description": intent_warnings[0] if intent_warnings else "ì•…ì˜ì  ì˜ë„ ê°ì§€",
                    "pattern": ""
                }],
                blocked_reason=intent_warnings[0] if intent_warnings else "ìš”ì²­ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
            ),
            execution_allowed=False,
            warnings=intent_warnings
        )
    
    # 2ë‹¨ê³„: Vertex AI ì¸ì¦ ì„¤ì •
    if config.vertex_credentials:
        _setup_vertex_auth(config)
    
    # 3ë‹¨ê³„: LLMì„ í†µí•œ SQL ìƒì„±
    prompt = _build_natural_language_to_sql_prompt(request)
    
    completion_kwargs = {
        "model": config.model,
        "messages": [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ìì—°ì–´ë¥¼ ì•ˆì „í•œ MySQL SELECT ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                          "ë³´ì•ˆì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ë©°, ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. "
                          "ë°ì´í„° ìˆ˜ì • ì¿¼ë¦¬(INSERT, UPDATE, DELETE, DROP ë“±)ëŠ” ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”."
            },
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.2,  # ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ ì˜¨ë„
        "max_tokens": config.max_tokens,
    }
    
    if config.model.startswith("vertex_ai/"):
        completion_kwargs["vertex_project"] = config.vertex_project
        completion_kwargs["vertex_location"] = config.vertex_location
    
    if config.api_key:
        completion_kwargs["api_key"] = config.api_key
    
    try:
        response = await litellm.acompletion(**completion_kwargs)
        content = response.choices[0].message.content.strip()
        
        # JSON ì¶”ì¶œ
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()
        
        llm_result = json.loads(content)
        
        # LLMì´ ì¿¼ë¦¬ ìƒì„±ì„ ê±°ë¶€í•œ ê²½ìš°
        if not llm_result.get("sql_query"):
            return GeneratedSqlResult(
                original_question=request.question,
                sql_query="",
                explanation=llm_result.get("explanation", "ì¿¼ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
                tables_used=llm_result.get("tables_used", []),
                security_check=SqlSecurityCheckResult(
                    is_safe=False,
                    risk_level=SecurityRiskLevel.MEDIUM.value,
                    violations=[],
                    blocked_reason=llm_result.get("explanation", "ì¿¼ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ),
                execution_allowed=False,
                warnings=llm_result.get("warnings", [])
            )
        
        sql_query = llm_result.get("sql_query", "")
        
        # 4ë‹¨ê³„: ìƒì„±ëœ SQL ë³´ì•ˆ ê²€ì‚¬
        security_result = check_sql_security(sql_query, request.question)
        
        # 5ë‹¨ê³„: ë³´ì•ˆ ê²€ì‚¬ í†µê³¼ ì‹œ SQL ì •ì œ
        if security_result.is_safe:
            sql_query = sanitize_sql_query(sql_query, request.max_rows)
            security_result.sanitized_query = sql_query
        
        all_warnings = intent_warnings + llm_result.get("warnings", [])
        
        return GeneratedSqlResult(
            original_question=request.question,
            sql_query=sql_query if security_result.is_safe else "",
            explanation=llm_result.get("explanation", ""),
            tables_used=llm_result.get("tables_used", []),
            estimated_rows=llm_result.get("estimated_rows"),
            security_check=security_result,
            execution_allowed=security_result.is_safe,
            warnings=all_warnings
        )
        
    except json.JSONDecodeError as e:
        return GeneratedSqlResult(
            original_question=request.question,
            sql_query="",
            explanation=f"LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}",
            tables_used=[],
            security_check=SqlSecurityCheckResult(
                is_safe=False,
                risk_level=SecurityRiskLevel.MEDIUM.value,
                violations=[],
                blocked_reason="LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"
            ),
            execution_allowed=False,
            warnings=[f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"]
        )
    except Exception as e:
        raise RuntimeError(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
